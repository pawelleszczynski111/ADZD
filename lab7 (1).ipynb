{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a3125ec-a8e2-44f0-ad8d-0d7cc212f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1104a08c-8edd-4f50-bdde-b1b56f154503",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db3473b0-c94d-4557-9375-60129fbd954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.functions import col, lit, round\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed475c79-a4f2-4a7a-88be-6e9e6084c622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/21 16:24:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://1bd71d017e90:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Apache SQL and Hive</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=Apache SQL and Hive>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"local[2]\")\\\n",
    "        .appName(\"Apache SQL and Hive\")\\\n",
    "        .config(\"spark.memory.offHeap.enabled\",\"true\")\\\n",
    "        .config(\"spark.memory.offHeap.size\",\"4g\")\\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()\n",
    "spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae7b593b-5dab-4155-ac4c-23ec62616a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('zamowienia.txt', header=True, inferSchema=True, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2eeea59-5526-4be3-a1f2-c4ad9607382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"zamowienia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a87d0c2-8b5e-46fa-9f62-1cee7938515d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/21 16:24:53 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "25/01/21 16:24:53 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "25/01/21 16:25:04 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "25/01/21 16:25:04 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@172.18.0.2\n",
      "25/01/21 16:25:04 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Table(name='zamowienia_bucketed', catalog='spark_catalog', namespace=['default'], description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='zamowienia', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bb9aac9-374e-49b3-8b8c-f975377258f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------------+------------+-----------+\n",
      "|  Kraj|Sprzedawca|Data zamowienia|idZamowienia|      Utarg|\n",
      "+------+----------+---------------+------------+-----------+\n",
      "|Polska|  Kowalski|     16.07.2003|       10248|  440,00 z|\n",
      "|Polska|  Sowiäski|     10.07.2003|       10249|1 863,40 z|\n",
      "|Niemcy|   Peacock|     12.07.2003|       10250|1 552,60 z|\n",
      "|Niemcy| Leverling|     15.07.2003|       10251|  654,06 z|\n",
      "|Niemcy|   Peacock|     11.07.2003|       10252|3 597,90 z|\n",
      "|Niemcy| Leverling|     16.07.2003|       10253|1 444,80 z|\n",
      "|Polska|  Kowalski|     23.07.2003|       10254|  556,62 z|\n",
      "|Polska|     Dudek|     15.07.2003|       10255|2 490,50 z|\n",
      "|Niemcy| Leverling|     17.07.2003|       10256|  517,80 z|\n",
      "|Niemcy|   Peacock|     22.07.2003|       10257|1 119,90 z|\n",
      "|Niemcy|   Davolio|     23.07.2003|       10258|1 614,88 z|\n",
      "|Niemcy|   Peacock|     25.07.2003|       10259|  100,80 z|\n",
      "|Niemcy|   Peacock|     29.07.2003|       10260|1 504,65 z|\n",
      "|Niemcy|   Peacock|     30.07.2003|       10261|  448,00 z|\n",
      "|Niemcy|  Callahan|     25.07.2003|       10262|  584,00 z|\n",
      "|Polska|     Dudek|     31.07.2003|       10263|1 873,80 z|\n",
      "|Polska|  Sowiäski|     23.08.2003|       10264|  695,62 z|\n",
      "|Niemcy|    Fuller|     12.08.2003|       10265|1 176,00 z|\n",
      "|Niemcy| Leverling|     31.07.2003|       10266|  346,56 z|\n",
      "|Niemcy|   Peacock|     06.08.2003|       10267|3 536,60 z|\n",
      "+------+----------+---------------+------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0258f481-6db2-41c3-8f42-0d5504b866ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  Kraj|\n",
      "+------+\n",
      "|Polska|\n",
      "|Polska|\n",
      "|Niemcy|\n",
      "|Niemcy|\n",
      "|Niemcy|\n",
      "|Niemcy|\n",
      "|Polska|\n",
      "|Polska|\n",
      "|Niemcy|\n",
      "|Niemcy|\n",
      "|Niemcy|\n",
      "|Niemcy|\n",
      "|Niemcy|\n",
      "|Niemcy|\n",
      "|Niemcy|\n",
      "|Polska|\n",
      "|Polska|\n",
      "|Niemcy|\n",
      "|Niemcy|\n",
      "|Niemcy|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select Kraj from zamowienia').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed2ee69b-fceb-4f29-8d7a-6f17f622a178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------------+------------+-----------+---+\n",
      "|  Kraj|Sprzedawca|Data zamowienia|idZamowienia|      Utarg| ID|\n",
      "+------+----------+---------------+------------+-----------+---+\n",
      "|Polska|  Kowalski|     16.07.2003|       10248|  440,00 z|  0|\n",
      "|Polska|  Sowiäski|     10.07.2003|       10249|1 863,40 z|  1|\n",
      "|Niemcy|   Peacock|     12.07.2003|       10250|1 552,60 z|  2|\n",
      "|Niemcy| Leverling|     15.07.2003|       10251|  654,06 z|  3|\n",
      "|Niemcy|   Peacock|     11.07.2003|       10252|3 597,90 z|  4|\n",
      "|Niemcy| Leverling|     16.07.2003|       10253|1 444,80 z|  5|\n",
      "|Polska|  Kowalski|     23.07.2003|       10254|  556,62 z|  6|\n",
      "|Polska|     Dudek|     15.07.2003|       10255|2 490,50 z|  7|\n",
      "|Niemcy| Leverling|     17.07.2003|       10256|  517,80 z|  8|\n",
      "|Niemcy|   Peacock|     22.07.2003|       10257|1 119,90 z|  9|\n",
      "+------+----------+---------------+------------+-----------+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"ID\", monotonically_increasing_id())\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e7acab8-4674-4532-ace4-ff8ed4d4afda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/21 16:25:09 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "25/01/21 16:25:09 WARN HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
      "25/01/21 16:25:09 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "25/01/21 16:25:09 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n"
     ]
    }
   ],
   "source": [
    "df.write.bucketBy(16, 'ID').mode('overwrite').sortBy('Sprzedawca').saveAsTable('zamowienia_bucketed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "825eaea1-47f3-41a7-9501-2205b69ae918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark-warehouse/zamowienia_bucketed/part-00000-ea843406-c83b-49f7-a732-f3f873b86478_00000.c000.snappy.parquet\n",
      "spark-warehouse/zamowienia_bucketed/part-00000-ea843406-c83b-49f7-a732-f3f873b86478_00001.c000.snappy.parquet\n",
      "spark-warehouse/zamowienia_bucketed/part-00000-ea843406-c83b-49f7-a732-f3f873b86478_00002.c000.snappy.parquet\n",
      "spark-warehouse/zamowienia_bucketed/part-00000-ea843406-c83b-49f7-a732-f3f873b86478_00003.c000.snappy.parquet\n",
      "spark-warehouse/zamowienia_bucketed/part-00000-ea843406-c83b-49f7-a732-f3f873b86478_00004.c000.snappy.parquet\n",
      "spark-warehouse/zamowienia_bucketed/part-00000-ea843406-c83b-49f7-a732-f3f873b86478_00005.c000.snappy.parquet\n",
      "spark-warehouse/zamowienia_bucketed/part-00000-ea843406-c83b-49f7-a732-f3f873b86478_00006.c000.snappy.parquet\n",
      "spark-warehouse/zamowienia_bucketed/part-00000-ea843406-c83b-49f7-a732-f3f873b86478_00007.c000.snappy.parquet\n",
      "spark-warehouse/zamowienia_bucketed/part-00000-ea843406-c83b-49f7-a732-f3f873b86478_00008.c000.snappy.parquet\n",
      "spark-warehouse/zamowienia_bucketed/part-00000-ea843406-c83b-49f7-a732-f3f873b86478_00009.c000.snappy.parquet\n",
      "spark-warehouse/zamowienia_bucketed/part-00000-ea843406-c83b-49f7-a732-f3f873b86478_00010.c000.snappy.parquet\n",
      "spark-warehouse/zamowienia_bucketed/part-00000-ea843406-c83b-49f7-a732-f3f873b86478_00011.c000.snappy.parquet\n",
      "spark-warehouse/zamowienia_bucketed/part-00000-ea843406-c83b-49f7-a732-f3f873b86478_00012.c000.snappy.parquet\n",
      "spark-warehouse/zamowienia_bucketed/part-00000-ea843406-c83b-49f7-a732-f3f873b86478_00013.c000.snappy.parquet\n",
      "spark-warehouse/zamowienia_bucketed/part-00000-ea843406-c83b-49f7-a732-f3f873b86478_00014.c000.snappy.parquet\n",
      "spark-warehouse/zamowienia_bucketed/part-00000-ea843406-c83b-49f7-a732-f3f873b86478_00015.c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!ls spark-warehouse/zamowienia_bucketed/*.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "352c82e5-b623-4011-85d0-c34eea7bf3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------------+------------+-----------+---+\n",
      "|  Kraj|Sprzedawca|Data zamowienia|idZamowienia|      Utarg| ID|\n",
      "+------+----------+---------------+------------+-----------+---+\n",
      "|Niemcy|  Callahan|     10.01.2004|       10402|2 713,50 z|154|\n",
      "|Niemcy|  Callahan|     26.02.2004|       10452|2 018,50 z|204|\n",
      "|Niemcy|  Callahan|     01.08.2004|       10614|  464,00 z|366|\n",
      "|Niemcy|  Callahan|     12.08.2004|       10623|1 336,95 z|375|\n",
      "|Niemcy|  Callahan|     11.09.2004|       10651|  397,80 z|403|\n",
      "|Niemcy|  Callahan|     20.03.2005|       10955|   74,40 z|707|\n",
      "|Niemcy|  Callahan|     31.03.2005|       10979|4 813,50 z|731|\n",
      "|Niemcy|  Callahan|     13.04.2005|       10997|1 885,00 z|749|\n",
      "|Niemcy|   Davolio|     13.12.2003|       10377|  863,60 z|129|\n",
      "|Niemcy|   Davolio|     11.09.2004|       10655|  154,40 z|407|\n",
      "+------+----------+---------------+------------+-----------+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.table('zamowienia_bucketed').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db5abf07-2399-48ca-ae18-a5bbbe7bfeec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='zamowienia_bucketed', catalog='spark_catalog', namespace=['default'], description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='zamowienia', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ccdabba-d475-477d-80b6-664d7d89100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7a14567-05dd-4076-b42f-5039b721e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dfs.withColumn('Utarg', F.regexp_replace('Utarg', ',', '.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b2e633d-118e-4997-974d-73beb032f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dfs.withColumn('Utarg', F.regexp_replace('Utarg', '[^0-9.,]', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff5b645e-83b7-45c5-85ab-293a25496910",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs.withColumn('Utarg', F.col('Utarg').cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96dfc786-f93c-422a-ae06-a2c337de9aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+---------------+------------+-------+---+\n",
      "|  Kraj|Sprzedawca|Data zamowienia|idZamowienia|  Utarg| ID|\n",
      "+------+----------+---------------+------------+-------+---+\n",
      "|Polska|  Kowalski|     16.07.2003|       10248| 440.00|  0|\n",
      "|Polska|  Sowiäski|     10.07.2003|       10249|1863.40|  1|\n",
      "|Niemcy|   Peacock|     12.07.2003|       10250|1552.60|  2|\n",
      "|Niemcy| Leverling|     15.07.2003|       10251| 654.06|  3|\n",
      "|Niemcy|   Peacock|     11.07.2003|       10252|3597.90|  4|\n",
      "|Niemcy| Leverling|     16.07.2003|       10253|1444.80|  5|\n",
      "|Polska|  Kowalski|     23.07.2003|       10254| 556.62|  6|\n",
      "|Polska|     Dudek|     15.07.2003|       10255|2490.50|  7|\n",
      "|Niemcy| Leverling|     17.07.2003|       10256| 517.80|  8|\n",
      "|Niemcy|   Peacock|     22.07.2003|       10257|1119.90|  9|\n",
      "+------+----------+---------------+------------+-------+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6482af0-ee51-4978-8808-0ff35b74a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.bucketBy(4, 'ID').mode('overwrite').sortBy('ID').saveAsTable('zamowienia_bucketed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb38caed-e235-4032-8e11-172fe1e13b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|  Kraj|       total_utarg|\n",
      "+------+------------------+\n",
      "|Niemcy|         894996.49|\n",
      "|Polska|333330.91000000003|\n",
      "+------+------------------+\n",
      "\n",
      "Czas zapytania na danych wiaderkowanych: 0.6358 sekundy\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "bucketed_df = spark.sql(\"SELECT Kraj, SUM(Utarg) AS total_utarg FROM zamowienia_bucketed GROUP BY Kraj\")\n",
    "bucketed_df.show()\n",
    "bucketed_time = time.time() - start_time\n",
    "print(f\"Czas zapytania na danych wiaderkowanych: {bucketed_time:.4f} sekundy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23ff78a6-5541-4c67-8d9a-74f0ac49135b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+\n",
      "|  Kraj|      total_utarg|\n",
      "+------+-----------------+\n",
      "|Niemcy|894996.4900000002|\n",
      "|Polska|333330.9099999999|\n",
      "+------+-----------------+\n",
      "\n",
      "Czas zapytania na danych niepodzielonych na wiaderka: 0.1429 sekundy\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "non_bucketed_df = df.groupBy(\"Kraj\").agg(F.sum(\"Utarg\").alias(\"total_utarg\"))\n",
    "non_bucketed_df.show()\n",
    "non_bucketed_time = time.time() - start_time\n",
    "print(f\"Czas zapytania na danych niepodzielonych na wiaderka: {non_bucketed_time:.4f} sekundy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba3ba286-3504-4f94-ac6c-7c8f2a69a9f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_ALREADY_EXISTS] Path file:/opt/spark/work-dir/zamowienia2 already exists. Set mode as \"overwrite\" to overwrite the existing path.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartitionBy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mKraj\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSprzedawca\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzamowienia2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/readwriter.py:1463\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1463\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [PATH_ALREADY_EXISTS] Path file:/opt/spark/work-dir/zamowienia2 already exists. Set mode as \"overwrite\" to overwrite the existing path."
     ]
    }
   ],
   "source": [
    "df.write.partitionBy(\"Kraj\", \"Sprzedawca\").format(\"csv\").save('zamowienia2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60771e9e-20ec-46c0-9e73-aa40dbbd0cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "filtered_df = df.filter(df[\"Kraj\"] == \"Polska\").groupBy(\"Sprzedawca\").agg(F.sum(\"Utarg\").alias(\"total_utarg\"))\n",
    "filtered_df.show()\n",
    "\n",
    "non_partitioned_time = time.time() - start_time\n",
    "print(f\"Czas zapytania na danych oryginalnych: {non_partitioned_time:.4f} sekundy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14ada58-ad53-4df8-a7b7-3802c969e3df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2d7a41-0b1a-401c-be02-00ba9c07dfbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
